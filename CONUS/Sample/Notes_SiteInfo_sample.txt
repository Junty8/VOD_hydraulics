#%%

# S1 = pd.read_csv('SiteInfo_reps_53.csv')
# SiteInfo = pd.read_csv('SiteInfo_US_full.csv')
# FIA = pd.read_csv('FIA_plots.csv')
# S2 = pd.merge(FIA,SiteInfo,how='left', on=['row', 'col']).drop(columns=['Unnamed: 0_x','Unnamed: 0_y','Unnamed: 0.1'])
# S_combined = pd.concat([S1,S2],axis=0).drop_duplicates().sort_values(['row','col']).reset_index().drop(columns=['index'])
# S_combined.to_csv('SiteInfo_sample.csv')
# SiteInfo = pd.read_csv('SiteInfo_sample.csv')
# SiteInfo = SiteInfo.drop(columns=['Unnamed: 0']).drop_duplicates()
# SiteInfo = SiteInfo[['row','col']].drop_duplicates()

# unique_row = np.unique(SiteInfo['row'])

# for r in unique_row:
#     subset = SiteInfo[SiteInfo['row']==r].reset_index()
#     col = subset['col'].values
#     for i in range(1,len(subset)):
#         if col[i]-col[i-1]<2: subset=subset.drop([i])
#     if r==unique_row[0]:
#         df = subset.copy()
#     else:
#         df = pd.concat([df,subset],axis = 0)
        
# US = pd.read_csv('SiteInfo_US_full.csv')

# SiteInfo = pd.merge(df,US,how='left',on=['row','col']).reset_index().drop(columns=['index','level_0','Unnamed: 0','Unnamed: 0.1'])
# SiteInfo.to_csv('SiteInfo_sample.csv')